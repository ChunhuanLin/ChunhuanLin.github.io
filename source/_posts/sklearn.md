---
title: sklearn
layout: post
updated: 2017-09-13
comments: True
mathJax: True
tags:
- notes
- machine learning
categories:
- notes
---

## 机器学习

### 监督学习


**监督学习**可以分为**分类**和**回归**这两个问题。具体模型如下：    

#### 1.广义线性模型

* 1.1 普通最小二乘  
  缺点：不适用于X的各项相关的情况。当数据的收集没有经过设计时，可能出现这种情况。  
  复杂度：使用X矩阵的奇异值分解来计算最小二乘解。如果X矩阵是[n,p]，则复杂度为(np^2)。

* 1.2 岭(Ridge)回归  
  在最小二乘的基础上，对系数进行惩罚，将其二次方项作为惩罚项。  
  - 岭回归的*正则化参数*可以通过cv来选择。使用`RidgeCV`函数即可。  

* 1.3 Lasso  
  用*l1范数*惩罚系数，使得系数更加稀疏，最终使结果得到一个稀疏的表示。因此，Lasso常用于压缩感知。
　** Lasso正则化系数的选择**  
  - 使用cv　
　　LassoCV：适用于高维且具有多重共线性（collinear regression，数据中某一个变量或某几个变量可以用其他变量的线性组合来表示，意味着数据存在一定程度的冗余）的数据。  
    LassoLarsCV：能够探索更多的正则项系数的相关值，如果样本数目相对特征数目较小，它比LassoCV更快。　　
　- 基于模型选择的信息准则　　
　　LassoLarsIC: 相比cv需要计算k+1次（k-fold），这种方法只要进行一次运算。然而这种方法是建立在对模型结果的自由度有一个合理的估计的基础上，需要有大量的样本并且假设模型是正确的。当特征数高于样本数目的时候，这个方法可能就崩了。　　

* Multi-task Lasso  
  预测一个联合多回归问题，ｙ是一个(n_sample, n_tasks)的2D矩阵。　　
　该方法下，算法对不同的任务，每一次对特征的选择都是一致的，能够保证比Lasso有更稳定的特征选择。　　
    

